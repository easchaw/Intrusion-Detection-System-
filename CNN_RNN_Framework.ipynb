{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Host Based Intrusion Detection System- Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "\n",
    "import tensorflow as tf\n",
    "from numpy import mean,std\n",
    "from tensorflow.python.client import device_lib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, TimeDistributed,Flatten,BatchNormalization,MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import GRU,LSTM\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "import random\n",
    "import os,glob\n",
    "import numpy,math\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.layers import merge\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from keras.layers import Activation, Dense\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## abstract the normal training data\n",
    "start_time=time.time()\n",
    "\n",
    "root=('C://Users//a.chawla//Desktop//IDS//ADFA-LD//Training_Data_Master')\n",
    "os.chdir(root)\n",
    "data =[]\n",
    "\n",
    "#print(os.listdir(root))\n",
    "for fname in glob.glob(\"*\"):\n",
    "    file = open(fname,\"r\")                     ## open and read the file \n",
    "    callSeqString = (file.read())\n",
    "    callSeq = callSeqString.split()            ## Split the characters \n",
    "    #print(callSeq)\n",
    "    callSeqInt = list(map(int, callSeq))       ## Convert Strings to Integers\n",
    "    #print (callSeqInt)\n",
    "    data.append([callSeqInt])\n",
    "    \n",
    "x1=[]\n",
    "for i in range(0,len(data)) :\n",
    "        x1.append(data[i][0])\n",
    "\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create the Multilayer Perceptron model'''\n",
    "\n",
    "nWords = 340\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(nWords,32,input_length=None))\n",
    "\n",
    "model.add(layers.Conv1D(64, 2, padding = 'same', activation=\"relu\"))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Conv1D(64, 2, padding = 'same', activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Conv1D(64, 2, padding = 'same', activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GRU(200,return_sequences=True))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(TimeDistributed(Dense(nWords+1, activation='softmax')))\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizers.Adam(lr=0.0001))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dynamically pad the sequence and train the model \n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "startIndex=0\n",
    "batchsize=32 ## batch size in which training will happen\n",
    "\n",
    "endIndex=batchsize\n",
    "totalBatches= int(len(x1)/batchsize)\n",
    "\n",
    "\n",
    "def train_epoch(x1,startIndex,endIndex):\n",
    "    losses = []\n",
    "    for batch_seq in range(totalBatches):\n",
    "        batch_seq=x1[startIndex:endIndex]\n",
    "        max_length=max(len(seq) for seq in batch_seq)\n",
    "        train_seq=pad_sequences(batch_seq,max_length, dtype=int)\n",
    "    \n",
    "        \n",
    "        temp_x=[]\n",
    "        temp_y=[]\n",
    "        for seq in train_seq:\n",
    "            seq_x = seq[None, :-1]\n",
    "            seq_y = seq[None, 1:, None]\n",
    "            temp_x.append(seq_x)\n",
    "            temp_y.append(seq_y)\n",
    "           \n",
    "        \n",
    "        result_x=np.array(temp_x).reshape(batchsize,max_length-1)\n",
    "        result_y=np.array(temp_y).reshape(batchsize, max_length-1, 1)\n",
    "        loss = model.train_on_batch(x=result_x, y=result_y)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        \n",
    "        startIndex=startIndex+batchsize\n",
    "        endIndex=endIndex+batchsize\n",
    "        loss = np.mean(losses)\n",
    "        model.reset_states()  \n",
    "    return loss\n",
    "    \n",
    "    \n",
    "n_epochs =100\n",
    "for epoch in range(n_epochs):\n",
    "    loss = train_epoch(x1,startIndex,endIndex)\n",
    "    print(epoch+1,loss)\n",
    "print(time.time()-start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fetch Attack Data\n",
    "\n",
    "root=('C://Users//a.chawla//Desktop//IDS//ADFA-LD//Attack_Data_Master')\n",
    "os.chdir(root)\n",
    "\n",
    "attackprobSeq =[]\n",
    "label=[]\n",
    "\n",
    "for dirname in glob.glob(\"*\"):\n",
    "    os.chdir(os.path.join(root,dirname))           ## Dynamically change the directory name \n",
    "    for fname in glob.glob(\"*\"):\n",
    "        file = open(fname,\"r\")                     ## open and read the file\n",
    "        callSeqString = file.read()\n",
    "        callSeq = callSeqString.split()            ## Split the characters \n",
    "        callSeqInt = list(map(int, callSeq))      ## Convert Strings to Integers\n",
    "        attackprobSeq.append([callSeqInt])\n",
    "        label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fetch Validation Data\n",
    "\n",
    "root=('C://Users//a.chawla//Desktop//IDS//ADFA-LD//Validation_Data_Master')\n",
    "os.chdir(root)\n",
    "\n",
    "#print(os.listdir(root))\n",
    "for fname in glob.glob(\"*\"):\n",
    "    file = open(fname,\"r\")                     ## open and read the file\n",
    "    #print(file)\n",
    "    callSeqString = file.read()\n",
    "    callSeq = callSeqString.split()            ## Split the characters \n",
    "    callSeqInt = list(map(int, callSeq))       ## Convert Strings to Integers\n",
    "    evalprobSeq.append([callSeqInt])\n",
    "    label.append(0)\n",
    "\n",
    "    \n",
    "evalprobSeq=[]\n",
    "\n",
    "for i in range(0,len(evalprobSeq)) :\n",
    "        evalprobSeq.append(evalprobSeq[i][0])      \n",
    "        \n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function call to calculate the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateProbability(callSeq):\n",
    "    pSum=0\n",
    "    encoded = np.array(callSeq)[None, :]\n",
    "    \n",
    "    \n",
    "    # predict a word in the vocabulary\n",
    "    yhat = model.predict(encoded)\n",
    "    temp = yhat[0]\n",
    "\n",
    "    for i in range(0, len(callSeq)-1):\n",
    "        next = callSeq[i+1]\n",
    "        p = -math.log10(temp[i][next])\n",
    "        pSum = pSum + p\n",
    "    return pSum/len(callSeq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Calculate the probability (lr=0.001)\n",
    "start_time=time.time()\n",
    "\n",
    "prob=[]\n",
    "for x in attackprobSeq:\n",
    "    p =(evaluateProbability(x))\n",
    "    prob.append(p)\n",
    "\n",
    "Mean_Attack= mean(prob[0:745])\n",
    "Std_dev_Attack= std(prob[0:745])\n",
    "\n",
    "## print the statistical measures\n",
    "print(Mean_Attack)\n",
    "print(Std_dev_Attack)\n",
    "\n",
    "\n",
    "## Validation Mean and SD\n",
    "Mean_Val= (mean(prob[746:5118]))\n",
    "Std_dev_Val= std(prob[746:5118])\n",
    "print(Mean_Val)\n",
    "print(Std_dev_Val)\n",
    "#print(len(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the Metrics and plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate FPR and TPR CNN+GRU 200 Units \n",
    "\n",
    "Thresh=np.arange(Mean_Val-1,Mean_Attack+1,.02,dtype='float32')\n",
    "\n",
    "print('No of Threshold values:',len(Thresh))\n",
    "print(Thresh)\n",
    "\n",
    "print('Probability values:',prob)\n",
    "print('---------------')\n",
    "tpr=[]\n",
    "fpr=[]\n",
    "pred=[]\n",
    "\n",
    "for i in Thresh:\n",
    "    for value in prob:\n",
    "        if(value>i):\n",
    "            pred.append(1)\n",
    "            \n",
    "        else:\n",
    "            pred.append(0)\n",
    "\n",
    "    \n",
    "    pred=np.array(pred, dtype=int)\n",
    "    conf = confusion_matrix(label,pred)\n",
    "\n",
    "    FP = conf[0,1]\n",
    "    TN = conf[0,0]\n",
    "    FN = conf[1,0]\n",
    "    TP = conf[1,1]\n",
    "    print('True Negatives:',TN)\n",
    "    print('False Positives:',FP)\n",
    "    print('False Negatives:',FN)\n",
    "    print('True Positives:',TP)\n",
    "    print('------------')\n",
    "    \n",
    "    true_positive_rate=TP/(TP+FN)\n",
    "    tpr.append(true_positive_rate)\n",
    "    #print(tpr)\n",
    "    \n",
    "    false_positive_rate=FP/(FP+TN)\n",
    "    fpr.append(false_positive_rate)\n",
    "    \n",
    "    pred=[]\n",
    "         \n",
    "tpr=np.array(tpr, dtype='float32')\n",
    "fpr=np.array(fpr,dtype='float32')\n",
    "\n",
    "\n",
    "print('Detection Rate:',tpr)\n",
    "print('False Alarm Rate:', fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.plot([0.0, 1.0], [0.0, 1.0], color='navy', lw=2, linestyle='--')\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr_LSTM,tpr_LSTM,color='deeppink', linestyle=':',lw=2,label='GRU with 200 (AUC = %0.2f)' % roc_auc)\n",
    "plt.xlabel(\"False Alarm Rate [%]\")\n",
    "plt.ylabel(\"Detection Rate [%]\")\n",
    "plt.title('Receiver operating characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
